// Licensed to Cloudera, Inc. under one
// or more contributor license agreements.  See the NOTICE file
// distributed with this work for additional information
// regarding copyright ownership.  Cloudera, Inc. licenses this file
// to you under the Apache License, Version 2.0 (the
// "License"); you may not use this file except in compliance
// with the License.  You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
{
  "name" : "SPARK",
  "label" : "Spark",
  "description" : "Apache Spark is an open source cluster computing system",
  "version" : "1.0",
  "runAs" : {
    "user" : "spark",
    "group" : "spark"
  },
  "inExpressWizard" : true,
  "icon" : "images/icon.png",
  "parcel" : {
    /* Automatically add the spark parcel repository */
    "repoUrl" : "http://archive.cloudera.com/spark/parcels/latest/",
    "requiredTags" : ["spark", "cdh"],
    "optionalTags" : ["spark-plugin"]
  },
  "serviceDependencies" : [
    {
      "name" : "HDFS",
      "required" : "false"
    }
  ],
  "commands" : [
    {
      "name" : "SparkUploadJarServiceCommand",
      "label" : "Upload Spark Jar",
      "description" : "Upload Spark assembly jar to HDFS.",
      "roleName" : "SPARK_MASTER",
      "roleCommand" : "SparkUploadJarCommand",
      "runMode" : "single"
    }
  ],
  "hdfsDirs" : [
    {
      "name" : "CreateSparkUserDirCommand",
      "label" : "Create Spark User Dir",
      "description" : "Creates the Spark user directory in HDFS.",
      "directoryDescription" : "Spark HDFS user directory",
      "path" : "/user/${user}",
      "permissions" : "0751"
    }
   ],
  "serviceInit" : {
    "preStartSteps" : [
      {
        "commandName" : "CreateSparkUserDirCommand"
      },
      {
        "commandName" : "SparkUploadJarServiceCommand",
        /** We allow a failure here because on kerberized clusters,
            this command will always fail **/
        "failureAllowed" : true
      }
    ]
  },
  "parameters" : [
    {
      "name" : "identity_string",
      "label" : "Identity String",
      "description" : "The identity string of the Spark instance",
      "configName" : "identity.string",
      "required" : "false",
      "type" : "string"
    },
    {
      "name" : "spark_jar_hdfs_path",
      "label" : "Spark Jar Location (HDFS)",
      "description" : "The location of the Spark jar in HDFS",
      "default" : "/user/spark/share/lib/spark-assembly.jar",
      "type" : "string"
    }
  ],
  "rolesWithExternalLinks" : ["SPARK_MASTER"],
  "roles" : [
    {
      "name" : "SPARK_MASTER",
      "label" : "Master",
      "pluralLabel" : "Masters",
      "startRunner" : {
        "program" : "scripts/control.sh",
        "args" : [
           "start_master",
           "./master.properties"
        ],
        "environmentVariables" : {
           "SPARK_DAEMON_MEMORY" : "${master_max_heapsize}",
           "SPARK_IDENT_STRING" : "${user}",
           "SPARK_MASTER_PORT" : "${master_port}",
           "SPARK_MASTER_WEBUI_PORT" : "${master_webui_port}",
           "ADDITIONAL_ARGS" : "${master_additional_args}"
        }
      },
      "commands" : [
        {
          "name" : "SparkUploadJarCommand",
          "label" : "Upload Spark Jar",
          "description" : "Upload Spark assembly jar to HDFS.",
          "expectedExitCodes" : [0],
          "requiredRoleState" : "stopped",
          "commandRunner" : {
            "program" : "scripts/control.sh",
            "args" : ["upload_jar"],
            "environmentVariables" : {
              "SPARK_JAR_HDFS_PATH" : "${spark_jar_hdfs_path}"
            }
          }
        }
      ],
      "externalLink" : {
        "name" : "master_web_ui",
        "label" : "Master Web UI",
        "url" : "http://${host}:${master_webui_port}"
      },
      "topology" : { "minInstances" : 1, "maxInstances" : 1 },
      "logging" : {
         "dir" : "/var/log/spark",
         "filename" : "spark-master-${host}.log",
         "configName" : "log.dir",
         "modifiable" : true,
         "loggingType" : "log4j"
      },
      "parameters" : [
        {
          "name" : "master_port",
          "label" : "Master Port",
          "description" : "The port of the master",
          "configName" : "server.port",
          "required" : "true",
          "type" : "port",
          "default" : 7077
        },
        {
          "name" : "master_webui_port",
          "label" : "Master WebUI Port",
          "description" : "The port of the master WebUI",
          "configName" : "webui.port",
          "required" : "true",
          "type" : "port",
          "default" : 18080
        },
        {
          "name" : "master_additional_args",
          "label" : "Additional Master args",
          "description" : "Additional arguments for the master",
          "configName" : "additional.args",
          "required" : "false",
          "type" : "string",
          "default" : ""
        },
        {
          "name" : "master_max_heapsize",
          "label" : "Java Heap Size of Master in Bytes",
          "description" : "Maximum size for the Java process heap memory. Passed to Java -Xmx. Measured in bytes.",
          "required" : "true",
          "type" : "memory",
          "unit" : "bytes",
          "min" : 67108864,
          "default" : 536870912,
          "scaleFactor" : 1.3
        }
      ],
      "configWriter" : {
        "peerConfigGenerators" : [
          {
            "filename" : "master.properties",
            "params" : ["master_port"],
            "roleName" : "SPARK_MASTER"
          }
        ]
      }
    },
    {
      "name" : "SPARK_WORKER",
      "label" : "Worker",
      "pluralLabel" : "Workers",
      "startRunner" : {
        "program" : "scripts/control.sh",
        "args" : [
           "start_worker",
           "./master.properties"
        ],
        "environmentVariables" : {
           "SPARK_DAEMON_MEMORY" : "${worker_max_heapsize}",
           "SPARK_IDENT_STRING" : "${user}",
           "SPARK_WORKER_PORT" : "${worker_port}",
           "SPARK_WORKER_WEBUI_PORT" : "${worker_webui_port}",
           "SPARK_WORKER_DIR" : "${work_directory}",
           "SPARK_WORKER_MEMORY" : "${executor_total_max_heapsize}",
           "ADDITIONAL_ARGS" : "${worker_additional_args}"
        }
      },
      "externalLink" : {
       "name" : "worker_web_ui",
       "label" : "Worker Web UI",
       "url" : "http://${host}:${worker_webui_port}"
      },
      "topology" : { "minInstances" : 1 },
      "logging" : {
        "dir" : "/var/log/spark",
        "filename" : "spark-worker-${host}.log",
        "configName" : "log.dir",
        "loggingType" : "log4j"
      },
      "parameters" : [
        {
          "name" : "worker_port",
          "label" : "Worker Port",
          "description" : "The port of the worker",
          "configName" : "server.port",
          "required" : "true",
          "type" : "port",
          "default" : 7078
        },
        {
          "name" : "worker_webui_port",
          "label" : "Worker WebUI Port",
          "description" : "The port of the worker WebUI",
          "configName" : "webui.port",
          "required" : "true",
          "type" : "port",
          "default" : 18081
        },
        {
          "name" : "worker_additional_args",
          "label" : "Additional Worker args",
          "description" : "Additional arguments for the workers",
          "configName" : "additional.args",
          "required" : "false",
          "type" : "string",
          "default" : ""
        },
        {
          "name" : "work_directory",
          "label" : "Work directory",
          "description" : "The work directory for temporary files",
          "configName" : "work.dir",
          "required" : "true",
          "type" : "path",
          "pathType" : "localDataDir",
          "default" : "/var/run/spark/work"
        },
        {
          "name" : "worker_max_heapsize",
          "label" : "Java Heap Size of Worker in Bytes",
          "description" : "Maximum size for the Java process heap memory. Passed to Java -Xmx. Measured in bytes.",
          "required" : "true",
          "type" : "memory",
          "unit" : "bytes",
          "min" : 67108864,
          "default" : 536870912,
          "scaleFactor" : 1.3
        },
        {
          "name" : "executor_total_max_heapsize",
          "label" : "Total Java Heap Sizes of Worker's Executors in Bytes",
          "description" : "Memory available to the Worker's Executors. This is the maximum sum total of all the Executors' Java heap sizes on this Worker node. Passed to Java -Xmx. Measured in bytes.",
          "required" : "true",
          "type" : "memory",
          "unit" : "bytes",
          "min" : 67108864,
          "default" : 8589934592,
          "scaleFactor" : 1.3,
          "autoConfigShare" : 100
        }
      ],
      "configWriter" : {
        "peerConfigGenerators" : [
          {
            "filename" : "master.properties",
            "params" : ["master_port"],
            "roleName" : "SPARK_MASTER"
          }
        ]
      },
      "cgroup" : {
        "cpu" : {
          "autoConfigured" : true
        },
        "blkio" : {
          "autoConfigured" : true
        }
      }
    }
  ],
  "gateway" : {
    "alternatives" : {
      "name" : "spark-conf",
      "priority" : 50,
      "linkRoot" : "/etc/spark"
    },
    "scriptRunner" : {
      "program" : "scripts/control.sh",
      "args" : [
        "client",
        "master.properties"
      ],
      "environmentVariables" : {
        "SPARK_JAR_HDFS_PATH" : "${spark_jar_hdfs_path}"
      }
    },
    "configWriter" : {
      "auxConfigGenerators" : [
        {
          "filename" : "spark-conf/spark-env.sh",
          "sourceFilename" : "aux/client/spark-env.sh"
        },
        {
          "filename" : "spark-conf/log4j.properties",
          "sourceFilename" : "aux/client/log4j.properties"
        }
      ],
      "peerConfigGenerators" : [
        {
          "filename" : "master.properties",
          "params" : ["master_port"],
          "roleName" : "SPARK_MASTER"
        }
      ]
    }
  }
}


